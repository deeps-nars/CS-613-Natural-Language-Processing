{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 of S Deepak Narayanan, 16110142"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. follows below \n",
    "### Question 1. is just to download the dataset, which has already been done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization using Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not used in this assignment\n",
    "from nltk.tokenize import sent_tokenize\n",
    "file = open('alice.txt').read()\n",
    "data_temp = sent_tokenize(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Dataset cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_temp = data\n",
    "for dt in range(len(data_temp)):\n",
    "    data_temp[dt] = data_temp[dt].replace('\\n', \"\")\n",
    "    data_temp[dt] = data_temp[dt].replace('\\n', \"\")\n",
    "    data_temp[dt] = data_temp[dt].replace('\\ ',\" \")\n",
    "    data_temp[dt] = data_temp[dt].replace('\"',' ' )\n",
    "    data_temp[dt] = data_temp[dt].replace(\"  \",\" \")\n",
    "data_final = []\n",
    "for data in data_temp:\n",
    "    data = '<s> '+data\n",
    "    data = data + ' </s>'\n",
    "    data_final.append(data)\n",
    "data_final = data_temp\n",
    "# Final Data is Data Final itself\n",
    "del data_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data_final, test_size = 0.2, random_state= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. follows below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram Model and MLE for Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_count = {}\n",
    "for data in data_final:\n",
    "    arr = data.split()\n",
    "    for elem in arr:\n",
    "        if elem in unigram_count:\n",
    "            unigram_count[elem]+=1\n",
    "        else:\n",
    "            unigram_count[elem]=1\n",
    "## Unigram Count is a dictionary that contains all the Unigrams with their number of occurrences in the corpus.\n",
    "total_count = sum(unigram_count.values())\n",
    "mle_unigram = {}\n",
    "for elem in unigram_count:\n",
    "    mle_unigram[elem] = unigram_count[elem]/total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Model and MLE for Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram Count contains all the bigrams with their number of occurrences in the corpus. \n",
    "bigram_count = {}\n",
    "for data in data_final:\n",
    "    tmp_arr = data.split()\n",
    "    for i in range(len(tmp_arr)):\n",
    "        try:\n",
    "            if (tmp_arr[i],tmp_arr[i+1]) in bigram_count:\n",
    "                bigram_count[(tmp_arr[i],tmp_arr[i+1])]+=1\n",
    "            if (tmp_arr[i], tmp_arr[i+1]) not in bigram_count:\n",
    "                 bigram_count[(tmp_arr[i],tmp_arr[i+1])]=1\n",
    "        except:\n",
    "            continue\n",
    "mle_bigram = {}\n",
    "for i in bigram_count:\n",
    "    mle_bigram[i] = bigram_count[i]/unigram_count[i[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram Count and MLE for Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_count = {}\n",
    "for data in data_final:\n",
    "    tmp_arr = data.split()\n",
    "    for i in range(len(tmp_arr)):\n",
    "        try:\n",
    "            if (tmp_arr[i],tmp_arr[i+1],tmp_arr[i+2]) in trigram_count:\n",
    "                trigram_count[(tmp_arr[i],tmp_arr[i+1],tmp_arr[i+2])]+=1\n",
    "            if (tmp_arr[i], tmp_arr[i+1],tmp_arr[i+2]) not in trigram_count:\n",
    "                 trigram_count[(tmp_arr[i],tmp_arr[i+1],tmp_arr[i+2])]=1\n",
    "        except:\n",
    "            continue\n",
    "mle_trigram = {}\n",
    "for i in trigram_count:\n",
    "    mle_trigram[i] = trigram_count[i]/bigram_count[(i[0],i[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadgram Count and MLE for Quadgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadgram_count = {}\n",
    "for data in data_final:\n",
    "    tmp_arr = data.split()\n",
    "    for i in range(len(tmp_arr)):\n",
    "        try:\n",
    "            if (tmp_arr[i],tmp_arr[i+1],tmp_arr[i+2], tmp_arr[i+3]) in quadgram_count:\n",
    "                quadgram_count[(tmp_arr[i],tmp_arr[i+1],tmp_arr[i+2], tmp_arr[i+3])]+=1\n",
    "            if (tmp_arr[i], tmp_arr[i+1],tmp_arr[i+2], tmp_arr[i+3]) not in quadgram_count:\n",
    "                 quadgram_count[(tmp_arr[i],tmp_arr[i+1],tmp_arr[i+2], tmp_arr[i+3])]=1\n",
    "        except:\n",
    "            continue\n",
    "mle_quadgram = {}\n",
    "for i in quadgram_count:\n",
    "    mle_quadgram[i] = quadgram_count[i]/trigram_count[(i[0],i[1], i[2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below unic, bigc, tric, quadc, contains the number of unigrams, bigrams, trigrams and quadgrams in the corpus. Using the entire corpus in this case. The number of possible ones is also covered in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of n-grams possible and those present are respectively\n",
      "1-gram 6277,6277\n",
      "2-gram 39400729,16646\n",
      "3-gram 247318375933,21014\n",
      "4-gram 1552417445731441,21314\n"
     ]
    }
   ],
   "source": [
    "unic = len(unigram_count)\n",
    "bigc = len(bigram_count)\n",
    "tric = len(trigram_count)\n",
    "quadc = len(quadgram_count)\n",
    "\n",
    "possible= {i:0 for i in range(1,5)}\n",
    "possible[1] = unic\n",
    "possible[2] = unic**2\n",
    "possible[3] = unic**3\n",
    "possible[4] = unic**4\n",
    "\n",
    "present = {1:unic, 2:bigc, 3:tric, 4:quadc}\n",
    "print(\"The total number of n-grams possible and those present are respectively\")\n",
    "for i in present:\n",
    "    print(str(i) + '-gram '+str(possible[i])+','+str(present[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. (b) Sentence Probabilities\n",
    "### I am randomly taking 10 sentences from the corpus and displaying their probability using the unigram, bigram, trigram and the quadgram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def prob_sent(sentence, ngram):\n",
    "    \n",
    "    # Probability of Formation of a sentence using a Unigram\n",
    "    if ngram==1:\n",
    "        flag = 1\n",
    "        array = sentence.split()\n",
    "        product = 0\n",
    "        for i in array:\n",
    "            try:\n",
    "                product+=mle_unigram[i]\n",
    "            except:\n",
    "                flag = 0\n",
    "                break\n",
    "        if(flag==0):\n",
    "            return 100\n",
    "        return product\n",
    "        \n",
    "            \n",
    "        '''\n",
    "        prob_unigram_sent = {}\n",
    "        for sentence in data_final:\n",
    "            array = sentence.split()\n",
    "            product = 1\n",
    "            for i in array:\n",
    "                product*=mle_unigram[i]\n",
    "            prob_unigram_sent[sentence] = product\n",
    "        '''\n",
    "        \n",
    "    # Probability of formation of a sentence using a bigram\n",
    "    if ngram==2:\n",
    "        flag = 1\n",
    "        array = sentence.split()\n",
    "        product = 0\n",
    "        for i in range(len(array)-1):\n",
    "            try:\n",
    "                product+=mle_bigram[(array[i],array[i+1])]\n",
    "            except:\n",
    "                flag = 0\n",
    "                break\n",
    "        if(flag==0):\n",
    "            return 100\n",
    "        return product\n",
    "    '''\n",
    "        prob_bigram_sent  = {}\n",
    "        for sentence in data_final:\n",
    "            array = sentence.split()\n",
    "            product = 1\n",
    "            for i in range(len(array)):\n",
    "                try:\n",
    "                    product*=mle_bigram[(array[i],array[i+1])]\n",
    "                except:\n",
    "                    continue\n",
    "            prob_bigram_sent[sentence] = product\n",
    "    '''\n",
    "    # Probability of sentence formation using trigrams\n",
    "    if ngram==3:\n",
    "        flag = 1\n",
    "        array = sentence.split()\n",
    "        product = 1\n",
    "        for i in range(len(array)-2):\n",
    "            try:\n",
    "                product+=log(mle_trigram[(array[i],array[i+1], array[i+2])])\n",
    "            except:\n",
    "                flag = 0\n",
    "                break\n",
    "        if(flag==0):\n",
    "            return 100\n",
    "        return product\n",
    "    '''\n",
    "    prob_trigram_sent  = {}\n",
    "    for sentence in data_final:\n",
    "        array = sentence.split()\n",
    "        product = 1\n",
    "        for i in range(len(array)):\n",
    "            try:\n",
    "                product*=mle_trigram[(array[i],array[i+1], array[i+2])]\n",
    "            except:\n",
    "                continue\n",
    "        prob_trigram_sent[sentence] = log(product)\n",
    "    '''\n",
    "    #Probability of a sentence using quadgram \n",
    "    if ngram==4:\n",
    "        flag = 1\n",
    "        array = sentence.split()\n",
    "        product = 0\n",
    "        for i in range(len(array)-3):\n",
    "            try:\n",
    "                product+=log(mle_quadgram[(array[i],array[i+1], array[i+2], array[i+3])])\n",
    "            except:\n",
    "                flag = 0\n",
    "                break\n",
    "        if(flag==0):\n",
    "            return 100\n",
    "        return product\n",
    "    '''\n",
    "    prob_quadgram_sent = {}\n",
    "    for sentence in data_final:\n",
    "        array = sentence.split()\n",
    "        product = 1\n",
    "        for i in range(len(array)):\n",
    "            try:\n",
    "                product*=mle_quadgram[(array[i],array[i+1], array[i+2], array[i+3])]\n",
    "            except:\n",
    "                continue\n",
    "        prob_quadgram_sent[sentence] = product\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results are below: If 100, then the probability is 0, else the values are those computed from log probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence chosen is \n",
      " ‘Their heads are gone, if it please your Majesty!’ the soldiers shoutedin reply.\n",
      "The Probability using 1 gram model is  0.07467901836502518\n",
      "The Probability using 2 gram model is  4.377369608762241\n",
      "The Probability using 3 gram model is  -4.12396397940326\n",
      "The Probability using 4 gram model is  -1.3862943611198906\n",
      "\n",
      "The sentence chosen is \n",
      " ‘Fetch me my gloves this moment!’Then came a little pattering of feet on the stairs.\n",
      "The Probability using 1 gram model is  0.11254672517471151\n",
      "The Probability using 2 gram model is  3.735406986988175\n",
      "The Probability using 3 gram model is  -6.414874040816802\n",
      "The Probability using 4 gram model is  -1.791759469228055\n",
      "\n",
      "The sentence chosen is \n",
      " The Lobster QuadrilleThe Mock Turtle sighed deeply, and drew the back of one flapper acrosshis eyes.\n",
      "The Probability using 1 gram model is  0.10832114415732164\n",
      "The Probability using 2 gram model is  5.8081405408229125\n",
      "The Probability using 3 gram model is  -2.4011973816621555\n",
      "The Probability using 4 gram model is  -0.6931471805599453\n",
      "\n",
      "The sentence chosen is \n",
      " Her first idea was that shehad somehow fallen into the sea, ‘and in that case I can go back byrailway,’ she said to herself.\n",
      "The Probability using 1 gram model is  0.17223305704534378\n",
      "The Probability using 2 gram model is  5.110736441600368\n",
      "The Probability using 3 gram model is  -12.072944535658555\n",
      "The Probability using 4 gram model is  -1.6094379124341003\n",
      "\n",
      "The sentence chosen is \n",
      " Alice crouched down among the trees as well asshe could, for her neck kept getting entangled among the branches, andevery now and then she had to stop and untwist it.\n",
      "The Probability using 1 gram model is  0.24841540711847876\n",
      "The Probability using 2 gram model is  8.167335288764459\n",
      "The Probability using 3 gram model is  -21.61627887987963\n",
      "The Probability using 4 gram model is  -0.6931471805599453\n",
      "\n",
      "The sentence chosen is \n",
      " See how eagerly the lobsters and the turtles all advance!\n",
      "The Probability using 1 gram model is  0.1419226393629124\n",
      "The Probability using 2 gram model is  3.13629490316384\n",
      "The Probability using 3 gram model is  -3.0943445622221004\n",
      "The Probability using 4 gram model is  0.0\n",
      "\n",
      "The sentence chosen is \n",
      " ‘That’s right!’ shouted the Queen.\n",
      "The Probability using 1 gram model is  0.05590768730700471\n",
      "The Probability using 2 gram model is  1.7157682775712515\n",
      "The Probability using 3 gram model is  0.083709268125845\n",
      "The Probability using 4 gram model is  0.0\n",
      "\n",
      "The sentence chosen is \n",
      " ‘Thinking again?’ the Duchess asked, with another dig of her sharplittle chin.\n",
      "The Probability using 1 gram model is  0.08678693320331544\n",
      "The Probability using 2 gram model is  4.685554147184243\n",
      "The Probability using 3 gram model is  -4.529429087511424\n",
      "The Probability using 4 gram model is  0.0\n",
      "\n",
      "The sentence chosen is \n",
      " Alice sighed wearily.\n",
      "The Probability using 1 gram model is  0.00804485616772306\n",
      "The Probability using 2 gram model is  0.20520833333333335\n",
      "The Probability using 3 gram model is  1.0\n",
      "The Probability using 4 gram model is  0\n",
      "\n",
      "The sentence chosen is \n",
      " Comehere directly, and get ready for your walk!” “Coming in a minute,nurse!\n",
      "The Probability using 1 gram model is  0.06854379977246872\n",
      "The Probability using 2 gram model is  4.52095833560361\n",
      "The Probability using 3 gram model is  -5.222576268071368\n",
      "The Probability using 4 gram model is  -0.6931471805599453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "sentence_list_test = []\n",
    "for i in range(10):\n",
    "    sentence_list_test.append(random.choice(data_final))\n",
    "for i in range(10):\n",
    "    print('The sentence chosen is \\n',sentence_list_test[i])\n",
    "    for j in range(4):\n",
    "         print('The Probability using '+str(j+1)+' gram model is ', prob_sent(sentence_list_test[i],j+1))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. (a) Generating Sentences by using MLEs for the N-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have to do something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5., Q6. and Q7. follow below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Add One Smoothing and Good Turing Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below cell finds all the possible bigrams and puts all of them in the bigram_total dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_total = {}\n",
    "for i in unigram_count:\n",
    "    for j in unigram_count:\n",
    "        bigram_total[(i,j)] = 0\n",
    "## Created above all the possible bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell below is used for performing Add-One Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_one = {}\n",
    "for data in bigram_total:\n",
    "    if data not in bigram_count:\n",
    "        add_one[data] = (1)/( unigram_count[data[0]]+ len(unigram_count))\n",
    "    else:\n",
    "        add_one[data] = (bigram_count[data]+1)/((unigram_count[data[0]]) + len(unigram_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drasatic Changes in Probabilties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.00031857279388340236\n",
      "0.5 0.00031852205765249244\n",
      "0.016666666666666666 0.00031560675398453525\n"
     ]
    }
   ],
   "source": [
    "## The drastic changes after Add One Smoothing are\n",
    "## Example 1\n",
    "print(mle_bigram[('pink', 'eyes')], add_one[('pink', 'eyes')])\n",
    "\n",
    "## Example 2\n",
    "print(mle_bigram[('book,’', 'thought')], add_one[('book,’', 'thought')])\n",
    "\n",
    "## Example 3\n",
    "print(mle_bigram[('or', 'conversations')], add_one[('or', 'conversations')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above change in MLEs is due to the fact that Add-One has taking too much mass from something that occurs and has assigned it to something that has never occurred. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity for Add_One Smoothing on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The perplexity of Add One Smoothing is  1427.1236631270838\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def add_one_perplexity(data):\n",
    "    prob = 0\n",
    "    count = 0\n",
    "    for i in data:\n",
    "        arr = i.split()\n",
    "        for j in range(len(arr)):\n",
    "            count+=1\n",
    "            #print(math.log(add_one[(arr[j],arr[j+1])]))\n",
    "            try:\n",
    "               \n",
    "                prob+=math.log(add_one[(arr[j],arr[j+1])])\n",
    "                #print('b')\n",
    "            except:\n",
    "                continue\n",
    "    return math.exp(-1/(count)*prob)\n",
    "print(' The perplexity of Add One Smoothing is ',add_one_perplexity(test_data))\n",
    "del add_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good Turing Count and discounting value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computed the count of the number of bigrams with a particular count\n",
    "good_turing = {}\n",
    "for i in bigram_count:\n",
    "    if bigram_count[i] in good_turing:\n",
    "        good_turing[bigram_count[i]]+=1\n",
    "    else:\n",
    "        good_turing[bigram_count[i]]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The below plot is almost a straight line for value <5. The discounting is ~0.6 for c<7.  \n",
    "Note that 0 has a very high count because of the fact that number of times a word occurs is the maximum. I have not taken till 10 because of missing N-c values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The discounting values are:  {0: 0.8591253153910849, 1: 0.1792881616670163, 2: 1.0109204368174727, 3: 1.6851851851851851, 4: 3.434065934065934, 5: 3.504, 6: 5.36986301369863, 7: 5.0, 8: 7.457142857142857}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "after_count = {}\n",
    "after_count[0] = good_turing[1]/(sum(good_turing.values()))\n",
    "for i in range(1,9):\n",
    "    after_count[i] = (good_turing[i+1]*(i+1))/(good_turing[i])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('c value used for c+1 estimation')\n",
    "plt.ylabel(' The discounting value obtained')\n",
    "plt.scatter(after_count.keys(),after_count.values())\n",
    "print(' The discounting values are: ', after_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If there is a missing N(c+1) or N(c), then I am using the bigram mle here. \n",
    "### Below is the computation of probabilities using Good Turing Smoothing on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = {}\n",
    "sum_ = len(bigram_count)\n",
    "for data in bigram_total:\n",
    "    if data not in bigram_count:\n",
    "        gt[data] = good_turing[1]/(sum(good_turing.values()))\n",
    "    else:\n",
    "        try:\n",
    "            gt[data] = (good_turing[bigram_count[data]]*bigram_count[data])/(good_turing[bigram_count[data]-1]*sum_)\n",
    "        except:\n",
    "            gt[data] = mle_bigram[data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity for Good Turing on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.44184960056846\n"
     ]
    }
   ],
   "source": [
    "def good_turing_perplexity(data):\n",
    "    prob = 0\n",
    "    count = 0\n",
    "    for i in data:\n",
    "        arr = i.split()\n",
    "        for j in range(len(arr)):\n",
    "            count+=1\n",
    "            #print(math.log(add_one[(arr[j],arr[j+1])]))\n",
    "            try:\n",
    "                prob+=math.log(gt[(arr[j],arr[j+1])])\n",
    "                #print('b')\n",
    "            except:\n",
    "                continue\n",
    "    return math.exp(-1/(count)*prob)\n",
    "print (good_turing_perplexity(test_data))\n",
    "del gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clearly among both Add-One and Good Turing, Good Turing performs ~ 15 times better with a perplexity value of 95.44 over Add-One's Perplexity Value of 1427.123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
